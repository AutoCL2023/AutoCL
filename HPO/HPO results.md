#All of the best hyperparameter settings are shown here
### Best results per learning problem obtained from EvoLearner after HPO in terms of max_runtime, tournament_size, height_limit, card_limit, use_data_properties, use_inverse, quality_func, value_splitter, 𝐹1-measure and 𝐴𝑐𝑐𝑢𝑟𝑎𝑐𝑦. The first line of each learning problem represents the best hyperparameters and results before HPO, the second line represents the best hyperparameters and results after HPO. The results are the best among the 3 runs:
<img width="614" alt="Evolearner" src="https://github.com/AutoCL2023/AutoCL/blob/main/Evolearner%20HPO.png">
###Best results per learning problem obtained from OCEL after HPO in terms of max_runtime in seconds, max_num_of_concepts_tested,iter_bound,quality_func, 𝐹1_measure and Accuracy. The first line of each learning problem represents the best hyperparameters and results before HPO, the second line represents the best hyperparameters and results after HPO. The results are the best among the 3 runs：


<img width="614" alt="Ocel" src="https://github.com/AutoCL2023/AutoCL/blob/main/OCEL%20HPO.png">

###Best results per learning problem obtained from CELOE after HPO in terms of max_runtime in seconds, max_num_of_concepts_tested,iter_bound,quality_func, 𝐹1_measure and Accuracy. The first line of each learning problem represents the best hyperparameters and results before HPO, the second line represents the best hyperparameters and results after HPO. The results are the best among the 3 runs：<img width="614" alt="Celoe" src="https://github.com/AutoCL2023/AutoCL/blob/main/CELOE%20HPO.png">
